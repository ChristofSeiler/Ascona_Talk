---
title: "Latent Class Regression for CyTOF Data"
output: html_document
author: Christof Seiler
date: May, 2017
params:
  num_cells: "10000"
  num_latent_classes: "2"
  num_bins: "8"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Goal

The goal is to use ``Latent Class Regression`` for CyTOF data with ``Stan``. In this code, we use variational inference to speedup computations. In practice, we recommend to do full sampling using Hamiltonian Monte Carlo. This is not shown here, because it usually takes a few hours to compute on 10,000 cells.

## Load Packages

```{r load_packages}
library(ggplot2)
library(magrittr)
library(stringr)
library(reshape2)
library(dplyr)
library(flowCore)
library(rstan)
```

## Load Data

Load sample table.

```{r}
sample_table = read.csv("sample_table_bodenmiller_2012.csv")
sample_table$file_name = as.character(sample_table$file_name)
sample_table$patient = as.factor(sample_table$patient)
sample_table$shortname = as.character(sample_table$shortname)
```

Load samples fcs files. 

```{r import}
sample_list = lapply(sample_table$file_name,function(file_name_fcs) {
  fcsB = read.FCS(file_name_fcs,transformation = FALSE)
  marker_names = colnames(fcsB)[str_detect(colnames(fcsB),"Dd")]
  marker_ids = which(colnames(fcsB) %in% marker_names)
  fcsB@exprs[,marker_ids]
})
length(sample_list)
```

Combine all samples into one data frame.

```{r}
combine_samples = function(sample_id) {
  sample_info = sample_table[sample_id,]
  cat(as.character(sample_info$file_name),"\n")
  sample = sample_list[[sample_id]]
  rownames(sample_info) = NULL
  data.frame(sample,sample_info)
}
df_samples = lapply(1:length(sample_list),combine_samples) %>%
  do.call(rbind,.)
dim(df_samples)
```

Plot cell counts per sample.

```{r}
ggobj = ggplot(data = df_samples, aes(patient, fill = condition)) + 
  geom_bar(position="dodge") +
  ggtitle("Cell Count")
ggobj
## print to pdf for slides
pdf("Cell_Count_Bodenmiller_2012.pdf",height = 3,width = 4)
print(ggobj)
dev.off()
```

Transform raw counts.

```{r}
num_markers = 33
df_samples[,1:num_markers] = asinh((df_samples[,1:num_markers])/5)
```

Plot transformed counts for all patient combined.

```{r}
ggplot(df_samples, aes(x = CD3.110.114.Dd, fill = condition)) + 
  geom_density(alpha=.3)
ggplot(df_samples, aes(x = CD3.110.114.Dd, fill = condition)) + 
  geom_histogram(binwidth=.5, alpha=.5, position="identity")
ggplot(df_samples, aes(x = CD3.110.114.Dd, fill = condition)) + 
  geom_histogram(binwidth=.5, position="dodge")
```

Plot each patient separately.

```{r}
plot_counts = function(protein_name) {
  df_marker = data.frame(expression = df_samples[,protein_name],
                         patient = df_samples$patient,
                         condition = df_samples$condition)
  ggplot(df_marker, aes(x = expression, color = condition)) + 
    geom_density() +
    facet_wrap(~ patient) + 
    ggtitle(protein_name) +
    xlab("arcsinh transformed counts")
}
for(marker_name in names(df_samples)[1:num_markers]) 
  plot_counts(marker_name) %>% print
```

## Latent Class Regression

The transformed count data are not normal. To handle possible multimodal distribution, we bin the transformed counts and store them in a huge contingency table. We then use tools from categorical data analysis.

```{r}
set.seed(1234)
num_cells = as.integer(params$num_cells)
subsample_ids = sample(x = nrow(df_samples),
                       size = num_cells,
                       replace = FALSE)
df_samples_subset = df_samples[subsample_ids,]
count_range = range(df_samples_subset[,1:num_markers])
num_bins = as.integer(params$num_bins)
bin_breaks = seq(count_range[1],count_range[2],diff(count_range)/num_bins)
bin_breaks[1] = -Inf
bin_breaks[length(bin_breaks)] = Inf
df_samples_binned = df_samples_subset
for(i in 1:num_markers)
  df_samples_binned[,i] = cut(df_samples_subset[,i],
                              breaks = bin_breaks,
                              labels = 1:num_bins)
```

Plot one marker.

```{r}
plot_binned_counts = function(protein_name) {
  df_marker = data.frame(expression = df_samples_binned[,protein_name],
                         patient = df_samples_binned$patient,
                         condition = df_samples_binned$condition)
  ggplot(df_marker, aes(x = expression, fill = condition)) + 
    geom_bar(position="dodge") +
    facet_wrap(~ patient) + 
    scale_x_discrete(limits = levels(df_samples_binned[,protein_name])) +
    ggtitle(protein_name) +
    xlab("arcsinh transformed binned counts")
}
for(marker_name in names(df_samples_binned)[1:num_markers]) 
  plot_binned_counts(marker_name) %>% print
```

### Bayesian Model

We build a model and perform parameter inference using Stan.

```{r}
model_code = 
"data {
  int<lower=1> N;            // num observations
  int<lower=1> D;            // num donors
  int<lower=1> R;            // num latent class
  int<lower=1> J;            // num markers (polytomous variables)
  int<lower=1> K;            // num of bins
  int<lower=1,upper=D> donor[N]; // donor indicator
  vector<lower=0>[K] alpha;  // class-conditional prior
  // no regression: vector<lower=0>[R] beta; // class-membership prior
  vector[2] x[N];
  int<lower=1,upper=K> y[N,J];
}
parameters {
  simplex[K] pi[R,J];       // class-conditional probability
  vector[R] eta[N];         // class-membership probability
  vector<lower=0>[R] sigma_e; // class-membership variance
  matrix[R,2] beta;         // regression coefficients
  matrix[R,2] z[D];         // donor random effects
  vector<lower=0>[2] sigma_z[D];
  vector<lower=0>[R] sigma_b;
}
transformed parameters {
  simplex[R] theta[N];
  for (n in 1:N)
    theta[n] = softmax(eta[n]);
}
model {
  // prior
  for (r in 1:R) {
    for (j in 1:J)
      pi[r,j] ~ dirichlet(alpha);
  }
  for (d in 1:D) {
    for (r in 1:R)
      z[d,r] ~ normal(0,sigma_z[d]);
  }
  sigma_b ~ cauchy(0, 0.5);
  for (r in 1:R)
    beta[r,2] ~ double_exponential(0, sigma_b[r]);
  // no regression: theta ~ dirichlet(beta);
  for (n in 1:N)
    eta[n] ~ normal(beta * x[n] + z[donor[n]] * x[n], sigma_e);
  // likelihood
  for (n in 1:N) {
    real target_class[R];
    for (r in 1:R) {
      target_class[r] = log(theta[n,r]);
      for (j in 1:J)
        target_class[r] = target_class[r] + log(pi[r,j][y[n,j]]);
    }
    target += log_sum_exp(target_class);
  }
}"
model = stan_model(model_code = model_code,
                   model_name = "lcr_model")
```

Prepare data.

```{r}
treatment_BCRXL = ifelse(df_samples_binned$condition == "Ref", 0, 1)
donor = as.numeric(df_samples_binned$patient)
x = cbind(intercept=1,treatment_BCRXL)
as.numeric.factor <- function(x) {as.numeric(levels(x))[x]}
y = df_samples_binned[,1:num_markers]
for(i in 1:ncol(y))
  y[,i] = as.numeric.factor(y[,i])
y = as.matrix(y)
N = nrow(y)
R = as.integer(params$num_latent_classes) # num of latent classes
J = ncol(y)
K = length(levels(df_samples_binned$CD3.110.114.Dd))
D = length(levels(df_samples_binned$patient)) # num of patients
stan_data = list(N = N,
                 R = R,
                 J = J,
                 K = K,
                 D = D,
                 alpha = rep(1/K,K),
                 x = x,
                 y = y,
                 donor = donor)
```

Variational inference.

```{r}
fit_vb = vb(model,
            data = stan_data,
            seed = 1)
par = rstan::extract(fit_vb)
```

Extract marginal class-membership probability.

```{r}
print_latent_class_labels = function(beta) {
  x_Ref = c(1,0); x_BCRXL = c(1,1)
  low_probs = 0.025; high_probs = 0.975
  df_theta = lapply(c(low_probs,high_probs),function(probs) {
    beta_probs = apply(beta,MARGIN = c(2,3),function(x) quantile(x,probs = probs))
    theta_ref = exp(beta_probs[1:R,] %*% x_Ref)
    theta_ref = theta_ref/sum(theta_ref)
    theta_BCRXL = exp(beta_probs[1:R,] %*% x_BCRXL)
    theta_BCRXL = theta_BCRXL/sum(theta_BCRXL)
    data.frame(latent_class = 1:R,
      ref = theta_ref,
      BCRXL = theta_BCRXL,
      probs = probs)
  }) %>% do.call(rbind,.)
  credible_class = function(r) {
    low_ref = subset(df_theta,latent_class == r & probs == low_probs)$ref
    high_ref = subset(df_theta,latent_class == r & probs == high_probs)$ref
    low_BCRXL = subset(df_theta,latent_class == r & probs == low_probs)$BCRXL
    high_BCRXL = subset(df_theta,latent_class == r & probs == high_probs)$BCRXL
    format_perc = function(num) {
      perc = round(num,digits = 3) * 100
      str_pad(perc, 4, pad = " ")
    }
    paste0("P(r=",r,"|cell is 'Ref')=[",format_perc(low_ref),",",format_perc(high_ref),"]%","\n",
           "P(r=",r,"|cell is 'BCRXL')=[",format_perc(low_BCRXL),",",format_perc(high_BCRXL),"]%")
  }
  latent_class_labels = sapply(1:R,function(r) credible_class(r)) 
  latent_class_labels
}
print_latent_class_labels(par$beta)
```

Extract class-conditional probabilities.

```{r fig.height=6,fig.width=10}
post_cat = function(pi,latent_class,probs) {
  cat_all = apply(pi,MARGIN = c(2,3,4),function(x) quantile(x,probs = probs))
  cat = cat_all[latent_class,,] %>% t %>% data.frame
  names(cat)[1:J] = names(df_samples_binned)[1:J]
  cat$percentile = 100*probs
  cat$bin = factor(1:nrow(cat))
  cat$latent_class = latent_class
  cat_long = melt(cat,id.vars = c("bin","percentile","latent_class"))
  cat_long
}
post_cat_summary = function(pi,latent_class) {
  cat_long = cbind(post_cat(pi,latent_class,0.5),
                   perc_low = post_cat(pi,latent_class,0.025)$value,
                   perc_up = post_cat(pi,latent_class,0.975)$value)
  cat_long$percentile = factor(cat_long$percentile)
  cat_long
}
cat_long_compare = lapply(1:R,function(r) post_cat_summary(par$pi,r)) %>%
  do.call(rbind,.)
cat_long_compare$latent_class = factor(cat_long_compare$latent_class)
levels(cat_long_compare$latent_class) = print_latent_class_labels(par$beta)
ggplot(cat_long_compare,aes(x = bin,y = value,fill = latent_class)) + 
  geom_bar(stat = "identity",position = position_dodge()) +
  geom_errorbar(position = position_dodge(.9), width = .2, aes(ymin = perc_low, ymax = perc_up)) +
  facet_wrap(~ variable,nrow = 5) +
  ggtitle(paste("Class-Conditional Probability with R =",R,"(VB)")) +
  theme(axis.title = element_blank()) +
  xlab("arcsinh transformed counts") +
  theme(legend.position = "bottom")
```

## Session Info

```{r session_info}
sessionInfo()
```
